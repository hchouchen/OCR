{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy,os\n",
    "import torch\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import models.crnn as crnn\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from keys import getAlphabet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,root,train=True,type='English'):\n",
    "        self.train = train\n",
    "        #图像增强，训练集使用totensor、归一化\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5,], [0.5,])\n",
    "        ])\n",
    "        #图像增强，验证集使用totensor、归一化\n",
    "        self.test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5,], [0.5,])\n",
    "        ])\n",
    "        if type == 'English':\n",
    "            self.img = np.load(os.path.join(root,'English-data.npy'))#读入图片\n",
    "            self.label = pd.read_csv(os.path.join(root,'English-label.csv')) #读入label\n",
    "            self.label = self.label['0'].values\n",
    "        else:\n",
    "            self.img = np.load(os.path.join(root,'Russian-data.npy'))#读入图片\n",
    "            self.label = pd.read_csv(os.path.join(root,'Russian-label.csv')) #读入label\n",
    "            self.label = self.label['0'].values\n",
    "        \n",
    "        self.train_img, self.test_img, self.train_label, self.test_label = train_test_split(self.img,self.label,test_size=0.25)\n",
    "        \n",
    "        self.train_img = np.reshape(self.train_img,(-1,32,128))\n",
    "        self.test_img = np.reshape(self.test_img,(-1,32,128))\n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        if self.train:#如果是“训练”模式\n",
    "            target = self.train_label[index]\n",
    "            img = self.train_img[index]\n",
    "            # 图片变换\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.train_transform(img)\n",
    "            return img,target\n",
    "        else:\n",
    "            target = self.test_label[index]\n",
    "            img = self.test_img[index]\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.test_transform(img)\n",
    "            return img,target\n",
    "            \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_img)\n",
    "        else:\n",
    "            return len(self.test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = 'Russian'\n",
    "weight_path = r'./'+type+'-weight.pth'\n",
    "pretrained = False\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "alphabet = getAlphabet(type)\n",
    "nclass = len(alphabet) + 1\n",
    "nh = 256\n",
    "ngpu = 1\n",
    "loss_avg = utils.averager()\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "criterion = nn.CTCLoss()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "train_dataset = ImageDataset(root=r'./',train=True,type=type)\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_dataset = ImageDataset(root=r'./',train=False,type=type)\n",
    "val_loader = DataLoader(dataset=val_dataset,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model = crnn.CRNN(32, 1, nclass, nh, ngpu)\n",
    "model.cuda()\n",
    "if pretrained:\n",
    "    model.load_state_dict(torch.load(weight_path))\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.1,momentum=0.9,weight_decay=0.00004)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01, betas=(0.5, 0.999))\n",
    "\n",
    "losses = [] \n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1,gamma=0.5)#每一个epoch，学习率减小到原来的50%\n",
    "for echo in range(10):\n",
    "    train_loss = 0#定义训练损失\n",
    "    train_acc = 0#定义训练准确度\n",
    "    model.train()#将网络转化为训练模式\n",
    "    \n",
    "    if np.mod(echo,5) == 4:\n",
    "        scheduler.step()\n",
    "    for i,(X,label) in enumerate(train_loader):\n",
    "        X = Variable(X).cuda()#包装tensor用于自动求梯度\n",
    "        text, length = converter.encode(label)\n",
    "        preds = model(X)\n",
    "        #out = F.log_softmax(preds)\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * preds.size(1)))\n",
    "        cost = criterion(preds, text, preds_size, length)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        loss_avg.add(cost)\n",
    "    losses.append(loss_avg.val())\n",
    "    print(\"echo:\"+' ' +str(echo))\n",
    "    print(\"train-loss:\" + ' ' + str(loss_avg.val()))\n",
    "    trloss, = plt.plot(losses)\n",
    "    loss_avg.reset()\n",
    "    \n",
    "    model.eval()\n",
    "    n_correct = 0\n",
    "    for i,(X,label) in enumerate(val_loader):\n",
    "        img = X\n",
    "        X = Variable(X).cuda()#包装tensor用于自动求梯度\n",
    "        text, length = converter.encode(label)\n",
    "        preds = model(X)\n",
    "        #out = F.log_softmax(preds)\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * preds.size(1)))\n",
    "        cost = criterion(preds, text, preds_size, length)\n",
    "        loss_avg.add(cost)\n",
    "        \n",
    "        _, preds = preds.max(2)\n",
    "        #preds = preds.squeeze(2)\n",
    "        preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "        sim_preds = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "        #print(sim_preds)\n",
    "        for pred, target in zip(sim_preds, label):\n",
    "            if pred.strip() == target.strip():\n",
    "                n_correct += 1\n",
    "\n",
    "    accuracy = n_correct / float(len(val_loader) * BATCH_SIZE)\n",
    "    eval_losses.append(loss_avg.val())\n",
    "    eval_acces.append(accuracy)\n",
    "    print(\"test-loss:\" + ' ' + str(loss_avg.val()))\n",
    "    print(\"accuracy:\"+' '+str(accuracy))\n",
    "    loss_avg.reset()\n",
    "    \n",
    "    teloss, = plt.plot(eval_losses)\n",
    "    plt.legend(handles=[trloss,teloss],labels=['train-loss','test-loss'],loc='upper right')\n",
    "    plt.show()\n",
    "    plt.plot(eval_acces)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(),weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self,root):\n",
    "        #图像增强，验证集使用totensor、归一化\n",
    "        self.test_transform = transforms.Compose([\n",
    "            transforms.Resize(size=[32,128]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5,], [0.5,])\n",
    "        ])\n",
    "        \n",
    "        self.filelist = []\n",
    "        file = os.listdir(root)\n",
    "        for filename in file:\n",
    "            self.filelist.append(root+'/'+filename)\n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        img = io.imread(self.filelist[index],as_gray=True)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.test_transform(img)\n",
    "        print(self.filelist[index])\n",
    "        return img,' '\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type = 'Russian'\n",
    "weight_path = r'./'+type+'-weight.pth'\n",
    "\n",
    "alphabet = getAlphabet(type)\n",
    "nclass = len(alphabet) + 1\n",
    "nh = 256\n",
    "ngpu = 1\n",
    "\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "criterion = nn.CTCLoss()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "test_dataset = testDataset(root=r'./test')\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=1,shuffle=False)\n",
    "\n",
    "test_model = crnn.CRNN(32, 1, nclass, nh, ngpu)\n",
    "test_model.cuda()\n",
    "test_model.load_state_dict(torch.load(weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test/test2.jpg\n",
      "./test/test3.jpg\n",
      "./test/test1.jpg\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "model.eval()#将网络转化为训练模式\n",
    "for i,(X,label) in enumerate(test_loader):\n",
    "    X = Variable(X).cuda()#包装tensor用于自动求梯度\n",
    "    preds = model(X)\n",
    "    preds_size = Variable(torch.IntTensor([preds.size(0)] * preds.size(1)))\n",
    "    _, preds = preds.max(2)\n",
    "    #preds = preds.squeeze(2)\n",
    "    preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "    sim_preds = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "    result.append(sim_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['модули иртибот', 'иртиботмодули ', 'модули иртибот']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
